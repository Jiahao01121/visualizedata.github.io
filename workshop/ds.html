<!DOCTYPE html>

<html>

    <head>
    
        <title>Visualized Workshop: The Visual Display of Uncertainty and Measurement Error</title>

        <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700,400italic,300italic,300,800' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" type="text/css" href="../styles/styles.css">
        <!-- // <script src="template.js"></script> -->

    </head>

    <body>

    	<h2>Data Science</h2>
        <p>Who needs sampling when you have data science? But, even when you have "all" the data, there is still potential for error in generalizing from a large corpus of data. Using the <a target="_blank" href='https://books.google.com/ngrams'>Google Books Ngram Viewer</a>, taking into consideration <a target="_blank" href='RDOexc.pdf'>its flaws</a>, how might we better convey the weaknesses of this tool and other tools like it? How might we convey the generalizability of methods that are based on large, exhaustive data sets? </p>


    </body>

</html>