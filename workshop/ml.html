<!DOCTYPE html>

<html>

    <head>
    
        <title>Visualized Workshop: The Visual Display of Uncertainty and Measurement Error</title>

        <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700,400italic,300italic,300,800' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" type="text/css" href="../styles/styles.css">
        <!-- // <script src="template.js"></script> -->

    </head>

    <body>

    	<h2>Machine Learning</h2>
        <p>Machine Learning algorithms (and the data behind them) have gotten much better at accurately predicting an outcome. But all algorithms are sometimes wrong. And some algorithms are <a target="_blank" href='ml.pdf'>mostly wrong</a>. How can we convey this to end users of these algorithms? How can we be more specific about the confidence we have for each prediction? </p>


    </body>

</html>